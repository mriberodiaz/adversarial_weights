{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.cuda as cuda\n",
    "import os\n",
    "\n",
    "# Local imports\n",
    "from models import AdversarialNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cudafy(use_gpu, seq, device=None):\n",
    "    \"\"\" If use_gpu is True, returns cuda version of everything in tuple seq\"\"\"\n",
    "    if use_gpu is False:\n",
    "        return tuple(_.cpu() for _ in seq)\n",
    "    else:\n",
    "        if device != None:\n",
    "            return tuple(_.to(device) for _ in seq)\n",
    "        else:\n",
    "            return tuple(_.cuda() for _ in seq)\n",
    "USE_GPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_epochs       = 10 # Total number of epochs\n",
    "adversary_pace = 2  # Once every k epochs\n",
    "batch_size     = 200\n",
    "\n",
    "# Dataset parameters\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Loader objects\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# TODO: Previous code had 'batch_size = 4' here, was that intentional?\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "# Currently unused\n",
    "classes = (str(i) for i in range(1, num_classes+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization target\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Adversarial network\n",
    "advNet = AdversarialNet()\n",
    "\n",
    "if USE_GPU: # if we can use the GPU, move the parameters onto the GPU\n",
    "    advNet.cuda()\n",
    "\n",
    "# Primary optimizer\n",
    "optimizer_min = optim.SGD(advNet.primary_weights, lr=0.01, momentum=0., nesterov=False)\n",
    "# Adversary optimizer\n",
    "# TODO: May need to give this more power (?)\n",
    "# Doesn't seem to do anything in its round currently\n",
    "optimizer_max = optim.SGD(advNet.adversary_weights, lr=0.01, momentum=0., nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization history logging\n",
    "history = []\n",
    "\n",
    "# Epochs\n",
    "for epoch in range(n_epochs):\n",
    "    # Averaged loss\n",
    "    running_loss = 0.\n",
    "    \n",
    "    # Primary optimization\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get data\n",
    "        inputs, labels = cudafy(USE_GPU, data) # If using GPU, move data onto GPU\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer_min.zero_grad()\n",
    "                \n",
    "        # Forward pass\n",
    "        outputs = advNet(inputs)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        # Cancel out gradients for the adversary\n",
    "        # TODO: Is this really needed if the optimizer only works with a subset of weights?\n",
    "        # Yes, otherwise gradient will accumulate?\n",
    "        # But we're gonna zero it when it's the adversary's turn anyways?\n",
    "        optimizer_max.zero_grad()\n",
    "        # Descend\n",
    "        optimizer_min.step()\n",
    "        \n",
    "        # Print statistics before adversary turn\n",
    "        # TODO: This currently spams the console, it's fine\n",
    "        print('[Primary, Epoch %d, batch %d] Crossentropy: %.3f' %\n",
    "              (epoch+1, i+1, loss.item()))\n",
    "        # Save history\n",
    "        # TODO: Save separate histories for primary, adversary, epoch, etc.\n",
    "        history.append(loss.item())\n",
    "        \n",
    "    # Adversary optimization - once every adversary_pace epochs\n",
    "    if epoch % adversary_pace == 0:\n",
    "        # Adversary optimization\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # Get data\n",
    "            inputs, labels = cudafy(USE_GPU, data) # if using GPU, move data onto GPU \n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer_max.zero_grad()\n",
    "                    \n",
    "            # Forward pass\n",
    "            outputs = advNet(inputs)\n",
    "            loss    = -criterion(outputs, labels)\n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "            # Cancel out gradients for the primary\n",
    "            # TODO: Same question as before\n",
    "            optimizer_min.zero_grad()\n",
    "            # Descend\n",
    "            optimizer_max.step()\n",
    "            \n",
    "            # Print statistics\n",
    "            print('[Adversary, Epoch %d, batch %d] Crossentropy: %.3f' %\n",
    "                  (epoch+1, i+1, -loss.item()))\n",
    "            # Save history\n",
    "            history.append(-loss.item())           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot raw global history\n",
    "plt.figure(); plt.plot(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
